{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SportsBERT\n",
    "  \n",
    "*Gian Favero and Michael Montemurri, Mila, 2024*\n",
    "\n",
    "This notebook performs the following steps for the 2025 NFL Big Data Bowl competition:\n",
    "1. Load the BERT model trained on sports text corpa.\n",
    "2. Fine-tune the model on the BigData25 data formatted as text.\n",
    "3. Train a shallow regressor to predict the xYardsGained and xWinProbAdded for various plays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The xPassRush dataframe contains all play + player data from each game. This block of code merges all defensive players for a given play into one row, where players are identified by position and suffixed by the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2480543/4166413347.py:4: DtypeWarning: Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/processed/df_xPassRush.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gameId  playId homeTeamAbbr visitorTeamAbbr  frameId  nflId  \\\n",
      "0  2022090800      56           LA             BUF       76  38577   \n",
      "1  2022090800      80           LA             BUF       23  38577   \n",
      "2  2022090800     101           LA             BUF       46  38577   \n",
      "3  2022090800     122           LA             BUF       78  38577   \n",
      "4  2022090800     167           LA             BUF       75  38577   \n",
      "\n",
      "    displayName position club  down  ...  xPassRush_ILB4  xPassRush_OLB1  \\\n",
      "0  Bobby Wagner      ILB   LA     1  ...             NaN             NaN   \n",
      "1  Bobby Wagner      ILB   LA     2  ...             NaN             NaN   \n",
      "2  Bobby Wagner      ILB   LA     1  ...             NaN        0.834283   \n",
      "3  Bobby Wagner      ILB   LA     2  ...             NaN        0.895475   \n",
      "4  Bobby Wagner      ILB   LA     2  ...             NaN        0.900457   \n",
      "\n",
      "  xPassRush_OLB2 xPassRush_OLB3 xPassRush_OLB4  xPassRush_S1 xPassRush_S2  \\\n",
      "0            NaN            NaN            NaN      0.238420     0.011381   \n",
      "1            NaN            NaN            NaN      0.011753     0.011381   \n",
      "2            NaN            NaN            NaN      0.011381     0.012700   \n",
      "3            NaN            NaN            NaN      0.011381     0.011381   \n",
      "4            NaN            NaN            NaN      0.014146     0.012387   \n",
      "\n",
      "   xPassRush_S3  xPassRush_S4 xPassRush_S5  \n",
      "0      0.011381           NaN          NaN  \n",
      "1      0.013166           NaN          NaN  \n",
      "2           NaN           NaN          NaN  \n",
      "3           NaN           NaN          NaN  \n",
      "4           NaN           NaN          NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "Index(['gameId', 'playId', 'homeTeamAbbr', 'visitorTeamAbbr', 'frameId',\n",
      "       'nflId', 'displayName', 'position', 'club', 'down', 'quarter',\n",
      "       'yardsToGo', 'possessionTeam', 'defensiveTeam', 'yardlineSide',\n",
      "       'yardlineNumber', 'gameClock', 'preSnapHomeScore',\n",
      "       'preSnapVisitorScore', 'event', 'offenseFormation', 'receiverAlignment',\n",
      "       'preSnapHomeTeamWinProbability', 'preSnapVisitorTeamWinProbability',\n",
      "       'pff_manZone', 'pff_passCoverage', 'wasInitialPassRusher', 'o_clean',\n",
      "       'a_clean', 's_clean', 'x_clean', 'y_clean', 'dir_clean',\n",
      "       'playDescription', 'playAction', 'passLocationType', 'rushLocationType',\n",
      "       'pff_runConceptPrimary', 'yardsGained', 'homeTeamWinProbabilityAdded',\n",
      "       'visitorTeamWinProbilityAdded', 'creptDist', 'center_y', 'hDist',\n",
      "       'center_x', 'losDist', 'xPassRush', 'positionCount', 'playerSuffix',\n",
      "       'xPassRush_CB1', 'xPassRush_CB2', 'xPassRush_CB3', 'xPassRush_CB4',\n",
      "       'xPassRush_CB5', 'xPassRush_DE1', 'xPassRush_DE2', 'xPassRush_DE3',\n",
      "       'xPassRush_DE4', 'xPassRush_IDL1', 'xPassRush_IDL2', 'xPassRush_IDL3',\n",
      "       'xPassRush_IDL4', 'xPassRush_ILB1', 'xPassRush_ILB2', 'xPassRush_ILB3',\n",
      "       'xPassRush_ILB4', 'xPassRush_OLB1', 'xPassRush_OLB2', 'xPassRush_OLB3',\n",
      "       'xPassRush_OLB4', 'xPassRush_S1', 'xPassRush_S2', 'xPassRush_S3',\n",
      "       'xPassRush_S4', 'xPassRush_S5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/processed/df_xPassRush.csv')\n",
    "\n",
    "# Filter for defensive players only\n",
    "defensive_players = df[df[\"club\"] != df[\"possessionTeam\"]].copy()\n",
    "\n",
    "# Add a unique identifier for each position within a play\n",
    "defensive_players[\"positionCount\"] = (\n",
    "    defensive_players.groupby([\"gameId\", \"playId\", \"position\"]).cumcount() + 1\n",
    ")\n",
    "\n",
    "# Create a unique column suffix for each player using their position\n",
    "defensive_players[\"playerSuffix\"] = defensive_players[\"position\"] + defensive_players[\"positionCount\"].astype(str)\n",
    "\n",
    "# Pivot the defensive player hDist and losDist data\n",
    "pivoted = defensive_players.pivot_table(\n",
    "    index=[\"gameId\", \"playId\"],\n",
    "    columns=\"playerSuffix\",\n",
    "    values=[\"xPassRush\"],\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "# Flatten the multi-level columns for easier readability\n",
    "pivoted.columns = [f\"{metric}_{suffix}\" for metric, suffix in pivoted.columns]\n",
    "\n",
    "# Reset index to merge with game context\n",
    "pivoted.reset_index(inplace=True)\n",
    "\n",
    "# Extract game context (assuming it doesn't vary within a play)\n",
    "game_context = defensive_players.drop_duplicates(subset=[\"gameId\", \"playId\"])\n",
    "\n",
    "# Merge pivoted data with game context\n",
    "result_df = pd.merge(game_context, pivoted, on=[\"gameId\", \"playId\"], how=\"left\")\n",
    "\n",
    "# compare result to original dataframe. It checks out. Since different plays will have different number of each position we generate cols for all and just use NaN for now\n",
    "print(result_df.head())\n",
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional data processing can occur here. Plays where the QB was sacked has no determinable outcome in terms of what the original play call was. As such, this should be excluded from the training data since it could have really been anything, and leaving it empty can allow the model to latch onto this to predict less yards gained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the dataframe by removing unnecessary columns\n",
    "game_context_columns = [\n",
    "        \"gameId\",\n",
    "        \"playId\",\n",
    "        \"homeTeamAbbr\",\n",
    "        \"visitorTeamAbbr\",\n",
    "        \"frameId\",\n",
    "        \"nflId\",\n",
    "        \"displayName\",\n",
    "        \"position\",\n",
    "        \"club\",\n",
    "        \"down\",\n",
    "        \"quarter\",\n",
    "        \"yardsToGo\",\n",
    "        \"possessionTeam\",\n",
    "        \"defensiveTeam\",\n",
    "        \"yardlineSide\",\n",
    "        \"yardlineNumber\",\n",
    "        \"gameClock\",\n",
    "        \"preSnapHomeScore\",\n",
    "        \"preSnapVisitorScore\",\n",
    "        \"preSnapHomeTeamWinProbability\",\n",
    "        \"preSnapVisitorTeamWinProbability\",\n",
    "        \"event\",\n",
    "    ]\n",
    "\n",
    "# Offensive formation, receiver alignment, and pre-snap win probabilities related to OC\n",
    "offense_columns = [\n",
    "        \"offenseFormation\",\n",
    "        \"receiverAlignment\",\n",
    "    ]\n",
    "\n",
    "# Defensive formation, pass coverage, and run concept related to DC\n",
    "defensive_columns = [\n",
    "        \"pff_manZone\",\n",
    "        \"pff_passCoverage\",\n",
    "        \"xPassRush\"\n",
    "]\n",
    "defensive_columns = [col for col in result_df.columns if any(prefix in col for prefix in defensive_columns)]\n",
    "defensive_columns.remove('xPassRush')\n",
    "\n",
    "# Play description, pass location, rush location, and PFF run concept related to play call\n",
    "play_columns = [\n",
    "        \"playDescription\",\n",
    "        \"playAction\",\n",
    "        \"passLocationType\",\n",
    "        \"rushLocationType\",\n",
    "        \"pff_runConceptPrimary\",\n",
    "    ]\n",
    "\n",
    "# Run play mappings (combine common run concepts)\n",
    "run_concept_mapping = {\n",
    "    \"outside zone\": \"zone\",\n",
    "    \"inside zone\": \"zone\",\n",
    "    \"pull lead\": \"power\",\n",
    "    \"power\": \"power\",\n",
    "    \"man\": \"power\",\n",
    "    \"trap\": \"power\",\n",
    "    \"counter\": \"misdirection\",\n",
    "    \"draw\": \"misdirection\",\n",
    "    \"fb run\": \"power\",\n",
    "    \"trick\": \"trick\",\n",
    "    \"undefined\": \"undefined\",\n",
    "}\n",
    "\n",
    "# Yards gained, event, and win probability added related to play outcome\n",
    "outcome_columns = [\n",
    "        \"yardsGained\",\n",
    "        \"homeTeamWinProbabilityAdded\",\n",
    "        \"visitorTeamWinProbilityAdded\",\n",
    "    ]\n",
    "\n",
    "# Combine all columns\n",
    "useful_columns = game_context_columns + offense_columns + defensive_columns + play_columns + outcome_columns\n",
    "\n",
    "df_reduced = result_df[useful_columns].copy()\n",
    "\n",
    "# Remove plays where the QB was sacked\n",
    "df_reduced = df_reduced[~df_reduced[\"playDescription\"].str.contains(\"sacked\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define functions to extract the relevant information from each row in the dataframe and form sentence prompts for a BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text):\n",
    "    # Remove leading and trailing spaces and double spaces\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def get_game_context(game_context):\n",
    "    quarter = game_context[\"quarter\"].values[0] if not pd.isna(game_context[\"quarter\"].values[0]) else \"N/A\"\n",
    "    down = game_context[\"down\"].values[0] if not pd.isna(game_context[\"down\"].values[0]) else \"N/A\"\n",
    "    yards_to_go = game_context[\"yardsToGo\"].values[0] if not pd.isna(game_context[\"yardsToGo\"].values[0]) else \"N/A\"\n",
    "    yardline_number = game_context[\"yardlineNumber\"].values[0] if not pd.isna(game_context[\"yardlineNumber\"].values[0]) else \"N/A\"\n",
    "    yardline_side = game_context[\"yardlineSide\"].values[0] if not pd.isna(game_context[\"yardlineSide\"].values[0]) else \"N/A\"\n",
    "    game_clock = game_context[\"gameClock\"].values[0] if not pd.isna(game_context[\"gameClock\"].values[0]) else \"N/A\"\n",
    "    pre_snap_home_score = game_context[\"preSnapHomeScore\"].values[0] if not pd.isna(game_context[\"preSnapHomeScore\"].values[0]) else \"N/A\"\n",
    "    pre_snap_visitor_score = game_context[\"preSnapVisitorScore\"].values[0] if not pd.isna(game_context[\"preSnapVisitorScore\"].values[0]) else \"N/A\" \n",
    "\n",
    "    home_team_abbr = game_context[\"homeTeamAbbr\"].values[0] if not pd.isna(game_context[\"homeTeamAbbr\"].values[0]) else \"N/A\"\n",
    "    visitor_team_abbr = game_context[\"visitorTeamAbbr\"].values[0] if not pd.isna(game_context[\"visitorTeamAbbr\"].values[0]) else \"N/A\"\n",
    "    possession_team = game_context[\"possessionTeam\"].values[0] if not pd.isna(game_context[\"possessionTeam\"].values[0]) else \"N/A\"\n",
    "\n",
    "    pre_snap_home_team_win_probability = game_context[\"preSnapHomeTeamWinProbability\"].values[0] if not pd.isna(game_context[\"preSnapHomeTeamWinProbability\"].values[0]) else \"N/A\"\n",
    "    pre_snap_visitor_team_win_probability = game_context[\"preSnapVisitorTeamWinProbability\"].values[0] if not pd.isna(game_context[\"preSnapVisitorTeamWinProbability\"].values[0]) else \"N/A\"\n",
    "\n",
    "    ret_str = f\"It is {quarter} quarter with {game_clock} left. It is {down} down with {yards_to_go} yards to go. The ball is on the {yardline_side} {yardline_number} yardline. The score is {home_team_abbr} {pre_snap_home_score} - {visitor_team_abbr} {pre_snap_visitor_score}. {possession_team} have the ball. Current win probability for {home_team_abbr} is {pre_snap_home_team_win_probability:.2f} and for {visitor_team_abbr} it is {pre_snap_visitor_team_win_probability:.2f}.\"\n",
    "\n",
    "    return ret_str\n",
    "\n",
    "def get_offensive_context(offense_context):\n",
    "    offense_formation = offense_context[\"offenseFormation\"].values[0] if not pd.isna(offense_context[\"offenseFormation\"].values[0]) else \"N/A\"\n",
    "    receiver_alignment = offense_context[\"receiverAlignment\"].values[0] if not pd.isna(offense_context[\"receiverAlignment\"].values[0]) else \"N/A\"\n",
    "\n",
    "    # Remove underscores and lowercase the text\n",
    "    offense_formation = offense_formation.lower().replace(\"_\", \" \")\n",
    "    receiver_alignment = receiver_alignment.lower().replace(\"_\", \" \")\n",
    "\n",
    "    ret_str = f\"The offense is in {offense_formation} formation with the receivers aligned in {receiver_alignment}.\"\n",
    "\n",
    "    return ret_str\n",
    "\n",
    "def get_defensive_context(defensive_context):\n",
    "    defensive_formation = defensive_context[\"pff_manZone\"].values[0] if not pd.isna(defensive_context[\"pff_manZone\"].values[0]) else \"N/A\"\n",
    "    pass_coverage = defensive_context[\"pff_passCoverage\"].values[0] if not pd.isna(defensive_context[\"pff_passCoverage\"].values[0]) else \"N/A\"\n",
    "\n",
    "    # Remove underscores and lowercase the text\n",
    "    defensive_formation = defensive_formation.lower().replace(\"_\", \" \")\n",
    "    pass_coverage = pass_coverage.lower().replace(\"_\", \" \")\n",
    "\n",
    "    ret_str = f\"The defense is in {defensive_formation} coverage with {pass_coverage} formation.\"\n",
    "\n",
    "    return ret_str\n",
    "\n",
    "def get_blitzer(defensive_context):\n",
    "    # check all columns prefixed with xPassRush\n",
    "    rushers = { 'CB': 0, 'S': 0, 'ILB': 0, 'OLB': 0, 'DE': 0, 'IDL': 0 }\n",
    "    for col in defensive_context.columns:\n",
    "        if \"xPassRush\" in col:\n",
    "            xPassRush = defensive_context[col].values[0] if not pd.isna(defensive_context[col].values[0]) else 0\n",
    "            if xPassRush > 0.2:\n",
    "                # split the column name to get the position\n",
    "                position = col.split(\"_\")[1]\n",
    "                position = position[:-1] if position[-1].isdigit() else position\n",
    "                rushers[position] += 1\n",
    "    ret_str = f\"The defense is rushing {rushers['CB']} cornerbacks, {rushers['S']} safeties, {rushers['ILB']} inside linebackers, {rushers['OLB']} outside linebackers, {rushers['DE']} defensive ends, and {rushers['IDL']} interior defensive linemen.\"\n",
    "    return ret_str\n",
    "\n",
    "def get_play_description(play_context):\n",
    "    # Replace NaN with a placeholder or handle it explicitly\n",
    "    playAction = play_context[\"playAction\"].values[0] if not pd.isna(play_context[\"playAction\"].values[0]) else \"N/A\"\n",
    "    passLocationType = play_context[\"passLocationType\"].values[0] if not pd.isna(play_context[\"passLocationType\"].values[0]) else \"N/A\"\n",
    "    rushLocationType = play_context[\"rushLocationType\"].values[0] if not pd.isna(play_context[\"rushLocationType\"].values[0]) else \"N/A\"\n",
    "    pff_runConceptPrimary = play_context[\"pff_runConceptPrimary\"].values[0] if not pd.isna(play_context[\"pff_runConceptPrimary\"].values[0]) else \"\"\n",
    "    playDescription = play_context[\"playDescription\"].values[0] if not pd.isna(play_context[\"playDescription\"].values[0]) else \"\"\n",
    "\n",
    "    if passLocationType != \"N/A\":\n",
    "        passLocationType = passLocationType.lower().replace(\"_\", \" \").split(\" \")[0] + \" box\"\n",
    "        \n",
    "        # Get the direction and depth from the play description\n",
    "        passDepth = \"short\" if \"short\" in playDescription else \"deep\" if \"deep\" in playDescription else \"\"\n",
    "        passDirection = \"left\" if \"left\" in playDescription else \"right\" if \"right\" in playDescription else \"middle\"\n",
    "\n",
    "        # In case of a disagreement in passDirection and passLocationType, use the passDirection from the play description\n",
    "        if passDirection == \"middle\" and passLocationType != \"inside box\":\n",
    "            passLocationType = \"inside box\"\n",
    "\n",
    "        if playAction:\n",
    "            ret_val = f\"play action {passDepth} {passLocationType} pass\"\n",
    "        else:\n",
    "            ret_val = f\"{passDepth} {passLocationType} pass\"\n",
    "    else:\n",
    "        pff_runConceptPrimary = pff_runConceptPrimary.lower().replace(\"_\", \" \")\n",
    "        # Simplify the run concept\n",
    "        if pff_runConceptPrimary in run_concept_mapping:\n",
    "            pff_runConceptPrimary = run_concept_mapping[pff_runConceptPrimary]\n",
    "        rushLocationType = rushLocationType.lower().replace(\"_\", \" \")\n",
    "        ret_val = f\"{pff_runConceptPrimary} run\"\n",
    "\n",
    "    ret_val = \"The offense play call is a \" + ret_val + \".\"\n",
    "\n",
    "    return remove_spaces(ret_val)\n",
    "\n",
    "def get_xWinProb_outcome(outcome_context):\n",
    "    home_team_abbr = outcome_context[\"homeTeamAbbr\"].values[0] if not pd.isna(outcome_context[\"homeTeamAbbr\"].values[0]) else \"N/A\"\n",
    "    visitor_team_abbr = outcome_context[\"visitorTeamAbbr\"].values[0] if not pd.isna(outcome_context[\"visitorTeamAbbr\"].values[0]) else \"N/A\"\n",
    "    possession_team = outcome_context[\"possessionTeam\"].values[0] if not pd.isna(outcome_context[\"possessionTeam\"].values[0]) else \"N/A\"\n",
    "    yards_gained = outcome_context[\"yardsGained\"].values[0] if not pd.isna(outcome_context[\"yardsGained\"].values[0]) else \"N/A\"\n",
    "    home_team_win_probability_added = outcome_context[\"homeTeamWinProbabilityAdded\"].values[0] if not pd.isna(outcome_context[\"homeTeamWinProbabilityAdded\"].values[0]) else \"N/A\"\n",
    "    visitor_team_win_probability_added = outcome_context[\"visitorTeamWinProbilityAdded\"].values[0] if not pd.isna(outcome_context[\"visitorTeamWinProbilityAdded\"].values[0]) else \"N/A\"\n",
    "\n",
    "    # Find out if the possession team is the home or visitor team\n",
    "    if possession_team == home_team_abbr:\n",
    "        win_probability_added = home_team_win_probability_added\n",
    "    else:\n",
    "        win_probability_added = visitor_team_win_probability_added\n",
    "\n",
    "    return win_probability_added\n",
    "\n",
    "def get_xYardsGained_outcome(outcome_context):\n",
    "    yards_gained = outcome_context[\"yardsGained\"].values[0] if not pd.isna(outcome_context[\"yardsGained\"].values[0]) else \"N/A\"\n",
    "\n",
    "    return yards_gained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take sample play\n",
    "sample_play = df_reduced\n",
    "\n",
    "# Extract the game context using the game_context_columns\n",
    "game_context = sample_play[game_context_columns]\n",
    "\n",
    "# Extract the offensive formation, receiver alignment, and pre-snap win probabilities using the offense_columns\n",
    "offense_context = sample_play[offense_columns]\n",
    "\n",
    "# Extract the defensive formation, pass coverage, and pass rush using the defensive_columns\n",
    "defense_context = sample_play[defensive_columns]\n",
    "\n",
    "# Extract the play description, play action, pass location, rush location, and run concept using the play_columns\n",
    "play_context = sample_play[play_columns]\n",
    "\n",
    "# Extract the yards gained, event, and win probability added using the outcome_columns\n",
    "outcome_columns += [\"homeTeamAbbr\", \"visitorTeamAbbr\", \"possessionTeam\"]\n",
    "outcome_context = sample_play[outcome_columns]\n",
    "\n",
    "# Get the prompts for each of the rows in the dataframe\n",
    "prompts = []\n",
    "labels = []\n",
    "desired_label = \"yardsGained\"\n",
    "for i in range(len(sample_play)):\n",
    "    row = sample_play.iloc[[i]]\n",
    "\n",
    "    game_context_str = get_game_context(row[game_context_columns])\n",
    "    offensive_context_str = get_offensive_context(row[offense_columns])\n",
    "    defensive_context_str = get_defensive_context(row[defensive_columns])\n",
    "    blitzer_str = get_blitzer(row[defensive_columns])\n",
    "    simple_play_call = get_play_description(row[play_columns])\n",
    "\n",
    "    prompt = f\"Play {i + 1}: {game_context_str} {offensive_context_str} {defensive_context_str} {blitzer_str} {simple_play_call}\"\n",
    "    prompts.append(prompt)\n",
    "\n",
    "    win_probability_added = get_xWinProb_outcome(row[outcome_columns])\n",
    "    yards_gained = get_xYardsGained_outcome(row[outcome_columns])\n",
    "\n",
    "    if desired_label == \"winProbabilityAdded\":\n",
    "        labels.append(round(win_probability_added, 4))\n",
    "    else:\n",
    "        labels.append(round(yards_gained, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly form Hugging Face model hub\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/SportsBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10317/10317 [00:02<00:00, 3580.51 examples/s]\n",
      "Map: 100%|██████████| 1290/1290 [00:00<00:00, 3910.26 examples/s]\n",
      "Map: 100%|██████████| 1290/1290 [00:00<00:00, 3868.52 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 10317\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1290\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1290\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Your data\n",
    "data = {\n",
    "    \"prompt\": prompts,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "# Convert labels to float\n",
    "data[\"labels\"] = [float(label) for label in data[\"labels\"]]\n",
    "\n",
    "# Create a dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Convert dataset to Pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_val, test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=0.1111, random_state=42)  # 10% of total goes to val\n",
    "\n",
    "# Convert splits back to Dataset format\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train),\n",
    "    \"validation\": Dataset.from_pandas(val),\n",
    "    \"test\": Dataset.from_pandas(test)\n",
    "})\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"prompt\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove the \"prompt\" column from the dataset (not in the map function)\n",
    "dataset = dataset.remove_columns([\"prompt\", \"__index_level_0__\"])\n",
    "dataset.set_format(type=\"torch\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train a regressor head on top of BERT/SportsBERT to get an xYards or xWPA prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/bert-base-uncased\", num_labels=1)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/bert-base-uncased\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/SportsBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/cim/faverog/BigData25/venv/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cim/faverog/BigData25/venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='405' max='405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [405/405 08:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>59.100998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>58.250061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>57.515442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>58.084133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>58.022552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cim/faverog/BigData25/venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=405, training_loss=74.28382040895062, metrics={'train_runtime': 540.1663, 'train_samples_per_second': 95.498, 'train_steps_per_second': 0.75, 'total_flos': 1.357246192799232e+16, 'train_loss': 74.28382040895062, 'epoch': 5.0})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "sports_model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/SportsBERT\", num_labels=1)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/sportsbert\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=sports_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play 1: It is 1 quarter with 15:00 left. It is 1 down with 10 yards to go. The ball is on the BUF 25 yardline. The score is LA 0 - BUF 0. BUF have the ball. Current win probability for LA is 0.41 and for BUF it is 0.59. The offense is in shotgun formation with the receivers aligned in 2x2. The defense is in zone coverage with cover 6-left formation. The defense is rushing 0 cornerbacks, 1 safeties, 0 inside linebackers, 0 outside linebackers, 1 defensive ends, and 3 interior defensive linemen. The offense play call is a short inside box pass.\n",
      "Prediction: 6.790478706359863\n",
      "Actual: 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Gather a sample prompt and label\n",
    "sample_prompt = prompts[0]\n",
    "sample_label = labels[0]\n",
    "\n",
    "print(sample_prompt)\n",
    "\n",
    "# Encode the prompt\n",
    "encoded_prompt = tokenizer(sample_prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Move the encoded prompt to the GPU\n",
    "encoded_prompt = {key: value.to(trainer.args.device) for key, value in encoded_prompt.items()}\n",
    "\n",
    "# Make a prediction\n",
    "base_model.eval()\n",
    "sports_model.eval()\n",
    "with torch.no_grad():\n",
    "    base_logits = base_model(**encoded_prompt).logits\n",
    "    sports_logits = sports_model(**encoded_prompt).logits\n",
    "\n",
    "# Convert logits to a prediction\n",
    "base_prediction = base_logits[0].item()\n",
    "sports_prediction = sports_logits[0].item()\n",
    "\n",
    "# Print the prediction and the actual label\n",
    "print(f\"Base Model Prediction: {base_prediction}\")\n",
    "print(f\"SportsBERT Prediction: {sports_prediction}\")\n",
    "print(f\"Actual: {sample_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
