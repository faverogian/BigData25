{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Pipeline\n",
    "  \n",
    "*Gian Favero and Michael Montemurri, Mila, 2024*\n",
    "\n",
    "This notebook performs the following steps for the 2025 NFL Big Data Bowl competition:\n",
    "1. Load raw data from `player_play.csv`, `plays.csv`, and `tracking_week_X.csv`.\n",
    "2. Clean and preprocess data. \n",
    "3. Save data to be used later on downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff0ebfcf610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "\n",
    "# Go back a directory to access the data folder\n",
    "os.chdir(os.path.join(root_dir, '..'))\n",
    "\n",
    "from scripts.data_cleaning import clean_data, aggregate_data, strip_unused_data\n",
    "\n",
    "# set manual custom seed for reproducibility\n",
    "def set_random_seed(value): \n",
    "    g = torch.manual_seed(value)   \n",
    "    np.random.seed(value)\n",
    "    random.seed(value)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    return g\n",
    "\n",
    "# set seed\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Steps\n",
    "\n",
    "1. Based on \"Uncovering Tackle Opportunities and Missed Opportunities\", a 2024 NFL Big Data Bowl Finalist\n",
    "2. All plays are flipped such that xy-coordinate based data is for a team driving left to right\n",
    "3. All player orientation (angle) is from a reference of 0 degrees (right) and rotates counter clockwise\n",
    "4. Plays nullified by penalties are removed (there are none)\n",
    "5. Plays that are a QB kneel, spike, or sneak are removed.\n",
    "6. Plays that occur when `preSnapHomeTeamWinProbability` or `preSnapVisitorTeamWinProbability` are greater than 95% are removed. This is commonly referred to as \"garbage time\" and the losing team often stat pads here.\n",
    "7. `player_play.csv` and `tracking_week_X.csv` are merged on the `[\"gameId\", \"playId\", \"nflId\"]` axes, \n",
    "which is then merged with plays.csv on the `[\"gameId\", \"playId\", \"nflId\"]` axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cim/faverog/BigData25/data/scripts\n",
      "INFO: Aggregating data from players, play data, tracking data, and players data into a master dataframe...\n",
      "INFO: Loaded 16124 rows of plays, 354727 rows of player plays, and 59327373 rows of player tracking data\n",
      "INFO: Aggregated dataframe has 56747802 rows\n",
      "INFO: Transforming orientation and direction angles so that 0° points from left to right, and increasing angle goes counterclockwise...\n",
      "INFO: Flipping plays so that they all run from left to right...\n",
      "INFO: Removing QB kneels, spikes, sneaks...\n",
      "INFO: 548174 rows removed\n",
      "INFO: Removing inactive frames...\n",
      "INFO: 55508016 rows removed\n",
      "INFO: Removing garbage time frames...\n",
      "INFO: 100408 rows removed\n",
      "INFO: Converting geometry variables from floats to int...\n",
      "INFO: Removing unused columns from dataframe...\n",
      "INFO: 95 columns removed\n",
      "shape: (5, 33)\n",
      "┌────────────┬────────┬─────────┬───────┬───┬─────────────┬─────────────┬─────────────┬────────────┐\n",
      "│ gameId     ┆ playId ┆ frameId ┆ nflId ┆ … ┆ rushLocatio ┆ pff_runConc ┆ yardsGained ┆ wasInitial │\n",
      "│ ---        ┆ ---    ┆ ---     ┆ ---   ┆   ┆ nType       ┆ eptPrimary  ┆ ---         ┆ PassRusher │\n",
      "│ i64        ┆ i64    ┆ i64     ┆ i64   ┆   ┆ ---         ┆ ---         ┆ i64         ┆ ---        │\n",
      "│            ┆        ┆         ┆       ┆   ┆ str         ┆ str         ┆             ┆ i64        │\n",
      "╞════════════╪════════╪═════════╪═══════╪═══╪═════════════╪═════════════╪═════════════╪════════════╡\n",
      "│ 2022090800 ┆ 56     ┆ 76      ┆ 35472 ┆ … ┆ null        ┆ null        ┆ 6           ┆ null       │\n",
      "│ 2022090800 ┆ 56     ┆ 146     ┆ 35472 ┆ … ┆ null        ┆ null        ┆ 6           ┆ null       │\n",
      "│ 2022090800 ┆ 56     ┆ 76      ┆ 42392 ┆ … ┆ null        ┆ null        ┆ 6           ┆ null       │\n",
      "│ 2022090800 ┆ 56     ┆ 146     ┆ 42392 ┆ … ┆ null        ┆ null        ┆ 6           ┆ null       │\n",
      "│ 2022090800 ┆ 56     ┆ 76      ┆ 42489 ┆ … ┆ null        ┆ null        ┆ 6           ┆ null       │\n",
      "└────────────┴────────┴─────────┴───────┴───┴─────────────┴─────────────┴─────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Set paths to local data files\n",
    "print(root_dir)\n",
    "players_fname = os.path.join(root_dir, \"../raw/players.csv\")\n",
    "plays_fname = os.path.join(root_dir, \"../raw/plays.csv\")\n",
    "player_play_fname = os.path.join(root_dir, \"../raw/player_play.csv\")\n",
    "tracking_fname_list = [os.path.join(root_dir, f\"../raw/tracking_week_{i}.csv\") for i in range(1,10)]\n",
    "\n",
    "# Aggregate data from the plays.csv, players.csv, and any tracking data into one aggregate dataframe.\n",
    "df = aggregate_data(\n",
    "    players_fname=players_fname, \n",
    "    plays_fname=plays_fname,\n",
    "    player_play_fname=player_play_fname, \n",
    "    tracking_fname_list=tracking_fname_list,\n",
    "    )\n",
    "\n",
    "# Preprocess and clean the data\n",
    "active_frames = 'presnap' # ['at_snap', 'presnap', 'postsnap', 'all']\n",
    "df_clean = clean_data(df, 'at_snap') \n",
    "\n",
    "# Reduce the size of the dataframe by removing unnecessary columns\n",
    "useful_columns = [\n",
    "        \"gameId\",\n",
    "        \"playId\",\n",
    "        \"frameId\",\n",
    "        \"nflId\",\n",
    "        \"displayName\",\n",
    "        \"position\",\n",
    "        \"club\",\n",
    "        \"possessionTeam\",\n",
    "        \"defensiveTeam\",\n",
    "        \"preSnapHomeScore\",\n",
    "        \"preSnapVisitorScore\",\n",
    "        \"quarter\",\n",
    "        \"gameClock\",\n",
    "        \"down\",\n",
    "        \"yardsToGo\",\n",
    "        \"yardlineNumber\",\n",
    "        \"yardlineSide\",\n",
    "        \"offenseFormation\",\n",
    "        \"receiverAlignment\",\n",
    "        \"preSnapHomeTeamWinProbability\",\n",
    "        \"preSnapVisitorTeamWinProbability\",\n",
    "        \"o_clean\",\n",
    "        \"a_clean\",\n",
    "        \"s_clean\",\n",
    "        \"x_clean\",\n",
    "        \"y_clean\",\n",
    "        \"dir_clean\",\n",
    "        \"playDescription\",\n",
    "        \"passLocationType\",\n",
    "        \"rushLocationType\",\n",
    "        \"pff_runConceptPrimary\",\n",
    "        \"yardsGained\",\n",
    "        \"wasInitialPassRusher\",\n",
    "    ]\n",
    "\n",
    "df_reduced = strip_unused_data(df_clean, useful_columns)\n",
    "\n",
    "print(df_reduced.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = True\n",
    "\n",
    "if csv:\n",
    "    # Save the cleaned data to a csv file\n",
    "    df_reduced.write_csv(os.path.join(root_dir, \"../processed/df_clean.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
